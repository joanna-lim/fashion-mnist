{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning: Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='../data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Test Harness\n",
    "Perform CNN on varying activation functions: [ReLU, LeakyReLU, ELU, PReLU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_harness import run_test_harness\n",
    "\n",
    "# control variables:\n",
    "fc_layer_size = 128 # change accordingly\n",
    "batch_size = 64 # change accordingly\n",
    "\n",
    "activation_fns = [nn.ReLU(), nn.LeakyReLU(), nn.ELU(), nn.PReLU()]\n",
    "accuracies = []\n",
    "for activation_fn in activation_fns:\n",
    "    print(f\"---Activation Function: {activation_fn}---\")\n",
    "    accuracy = run_test_harness(train_dataset, test_dataset, batch_size, fc_layer_size, activation_fn)\n",
    "    accuracies.append((activation_fn, accuracy))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
