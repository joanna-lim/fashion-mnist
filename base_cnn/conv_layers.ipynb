{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='../data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/joannalim/Documents/AY23_24 Sem 1/SC4001/group assignment/SC4001-Group-Assignment/base_cnn/conv_layers.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joannalim/Documents/AY23_24%20Sem%201/SC4001/group%20assignment/SC4001-Group-Assignment/base_cnn/conv_layers.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m activation_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mPReLU()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joannalim/Documents/AY23_24%20Sem%201/SC4001/group%20assignment/SC4001-Group-Assignment/base_cnn/conv_layers.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m train_loader, test_loader \u001b[39m=\u001b[39m load_dataset(train_dataset, test_dataset, batch_size)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joannalim/Documents/AY23_24%20Sem%201/SC4001/group%20assignment/SC4001-Group-Assignment/base_cnn/conv_layers.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_loader, test_loader \u001b[39m=\u001b[39m prep_pixels(train_loader, test_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joannalim/Documents/AY23_24%20Sem%201/SC4001/group%20assignment/SC4001-Group-Assignment/base_cnn/conv_layers.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model1 \u001b[39m=\u001b[39m define_model(fc_layer_size, activation_fn)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joannalim/Documents/AY23_24%20Sem%201/SC4001/group%20assignment/SC4001-Group-Assignment/base_cnn/conv_layers.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m start_time1 \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/Documents/AY23_24 Sem 1/SC4001/group assignment/SC4001-Group-Assignment/base_cnn/test_harness.py:22\u001b[0m, in \u001b[0;36mprep_pixels\u001b[0;34m(train_loader, test_loader)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m train_loader\u001b[39m.\u001b[39mdataset:\n\u001b[1;32m     20\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfloat() \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfor\u001b[39;49;00m data, target \u001b[39min\u001b[39;49;00m test_loader\u001b[39m.\u001b[39;49mdataset:\n\u001b[1;32m     23\u001b[0m         data \u001b[39m=\u001b[39;49m data\u001b[39m.\u001b[39;49mfloat() \u001b[39m/\u001b[39;49m \u001b[39m255.0\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m train_loader, test_loader\n",
      "File \u001b[0;32m~/Documents/AY23_24 Sem 1/SC4001/group assignment/SC4001-Group-Assignment/venv/lib/python3.11/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(img\u001b[39m.\u001b[39;49mnumpy(), mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/Documents/AY23_24 Sem 1/SC4001/group assignment/SC4001-Group-Assignment/venv/lib/python3.11/site-packages/PIL/Image.py:3118\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3116\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n\u001b[0;32m-> 3118\u001b[0m \u001b[39mreturn\u001b[39;00m frombuffer(mode, size, obj, \u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m, rawmode, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/AY23_24 Sem 1/SC4001/group assignment/SC4001-Group-Assignment/venv/lib/python3.11/site-packages/PIL/Image.py:3026\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m _MAPMODES:\n\u001b[1;32m   3025\u001b[0m     im \u001b[39m=\u001b[39m new(mode, (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[0;32m-> 3026\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39m_new(core\u001b[39m.\u001b[39;49mmap_buffer(data, size, decoder_name, \u001b[39m0\u001b[39;49m, args))\n\u001b[1;32m   3027\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   3028\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m ImagePalette\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from test_harness import load_dataset, prep_pixels, define_model, define_model2, define_model3, train_and_evaluate_model_kfold\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import datetime\n",
    "\n",
    "# optimal hyperparameters:\n",
    "batch_size = 64\n",
    "fc_layer_size = 512\n",
    "activation_fn = nn.PReLU()\n",
    "\n",
    "train_loader, test_loader = load_dataset(train_dataset, test_dataset, batch_size)\n",
    "train_loader, test_loader = prep_pixels(train_loader, test_loader)\n",
    "\n",
    "model1 = define_model(fc_layer_size, activation_fn)\n",
    "start_time1 = datetime.datetime.now()\n",
    "accuracy1 = train_and_evaluate_model_kfold(model1, train_dataset, test_dataset, batch_size)\n",
    "end_time1 = datetime.datetime.now()\n",
    "print(\"Time taken: \", end_time1 - start_time1)\n",
    "\n",
    "model2 = define_model2(fc_layer_size, activation_fn)\n",
    "start_time2 = datetime.datetime.now()\n",
    "accuracy2 = train_and_evaluate_model_kfold(model2, train_dataset, test_dataset, batch_size)\n",
    "end_time2 = datetime.datetime.now()\n",
    "print(\"Time taken: \", end_time2 - start_time2)\n",
    "\n",
    "model3 = define_model3(fc_layer_size, activation_fn)\n",
    "start_time3 = datetime.datetime.now()\n",
    "accuracy3 = train_and_evaluate_model_kfold(model3, train_dataset, test_dataset, batch_size)\n",
    "end_time3 = datetime.datetime.now()\n",
    "print(\"Time taken: \", end_time3 - start_time3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
